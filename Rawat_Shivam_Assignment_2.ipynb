{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c80d2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5265ea4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/shivamsinghrawat/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/shivamsinghrawat/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download required NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c23927f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Function get dataframe from text file\n",
    "def load_txt_data(filepath):\n",
    "    \n",
    "    texts = []\n",
    "    labels = []\n",
    "    \n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
    "        lines = file.readlines()\n",
    "        \n",
    "        \n",
    "        for line in lines[1:]:  \n",
    "            parts = line.strip().split(\"\\t\")  \n",
    "            \n",
    "            print(len(parts))\n",
    "            \n",
    "            if len(parts) < 2:\n",
    "                parts = line.strip().split()  \n",
    "            \n",
    "            if len(parts) >= 2:\n",
    "                tweet = \" \".join(parts[1:-1])  \n",
    "                label = parts[-1]  \n",
    "                texts.append(tweet)\n",
    "                \n",
    "                \n",
    "                sentiment_mapping = {\n",
    "                    \"0: neutral or mixed emotional state can be inferred\": 0,\n",
    "                    \"1: slightly positive emotional state can be inferred\": 1,\n",
    "                    \"2: moderately positive emotional state can be inferred\": 2,\n",
    "                    \"3: very positive emotional state can be inferred\": 3,\n",
    "                    \"-1: slightly negative emotional state can be inferred\": -1,\n",
    "                    \"-2: moderately negative emotional state can be inferred\": -2,\n",
    "                    \"-3: very negative emotional state can be inferred\": -3\n",
    "                }\n",
    "                \n",
    "                \n",
    "                labels.append(sentiment_mapping.get(label, np.nan))\n",
    "    \n",
    "    df = pd.DataFrame({\"Tweet\": texts, \"Sentiment\": labels})\n",
    "    \n",
    "    df.dropna(inplace=True)\n",
    "    df[\"Sentiment\"] = df[\"Sentiment\"].astype(int)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "598a17d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Loading training data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_data \u001b[38;5;241m=\u001b[39m load_txt_data(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 36\u001b[0m, in \u001b[0;36mload_txt_data\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m     22\u001b[0m             texts\u001b[38;5;241m.\u001b[39mappend(tweet)\n\u001b[1;32m     25\u001b[0m             sentiment_mapping \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     26\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0: neutral or mixed emotional state can be inferred\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     27\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1: slightly positive emotional state can be inferred\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-3: very negative emotional state can be inferred\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m\n\u001b[1;32m     33\u001b[0m             }\n\u001b[0;32m---> 36\u001b[0m             labels\u001b[38;5;241m.\u001b[39mappend(sentiment_mapping\u001b[38;5;241m.\u001b[39mget(label, np\u001b[38;5;241m.\u001b[39mnan))\n\u001b[1;32m     38\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTweet\u001b[39m\u001b[38;5;124m\"\u001b[39m: texts, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSentiment\u001b[39m\u001b[38;5;124m\"\u001b[39m: labels})\n\u001b[1;32m     40\u001b[0m df\u001b[38;5;241m.\u001b[39mdropna(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Loading training data\n",
    "train_data = load_txt_data(\"train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cd1d187",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading test datasets\n",
    "test_data = load_txt_data(\"test.txt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f84603ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews in the training set: 1181\n"
     ]
    }
   ],
   "source": [
    "num_train_reviews = len(train_data)\n",
    "print(f\"Number of reviews in the training set: {num_train_reviews}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0388908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews in the testing set: 937\n"
     ]
    }
   ],
   "source": [
    "num_test_reviews = len(test_data)\n",
    "print(f\"Number of reviews in the testing set: {num_test_reviews}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7f79714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@liamch88 yeah! :) playing well  valence</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>At least I don't have a guy trying to discoura...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UPLIFT: If you're still discouraged it means y...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>...at your age, the heyday in the blood is tam...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was so embarrassed when she saw us i was lik...</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Sentiment\n",
       "0           @liamch88 yeah! :) playing well  valence          0\n",
       "1  At least I don't have a guy trying to discoura...          0\n",
       "2  UPLIFT: If you're still discouraged it means y...          0\n",
       "3  ...at your age, the heyday in the blood is tam...          0\n",
       "4  i was so embarrassed when she saw us i was lik...         -2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058081e9",
   "metadata": {},
   "source": [
    "## POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6635d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "# # Download the NLTK tagger model, if necessary. You can comment this out once the tagger is downloaded.\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('averaged_perceptron_tagger_eng')\n",
    "\n",
    "# class for tokenization\n",
    "class Splitter(object):\n",
    "    # load the tokenizer\n",
    "    def __init__(self):\n",
    "        self.nltk_splitter = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "        self.nltk_tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
    "    #split input \n",
    "    def split(self, text):\n",
    "        sentences = self.nltk_splitter.tokenize(text)\n",
    "        tokenized_sentences = [self.nltk_tokenizer.tokenize(sent) for sent in sentences]\n",
    "        return tokenized_sentences\n",
    "\n",
    "# class for POS tagging\n",
    "class POSTagger(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def pos_tag(self, sentences):\n",
    "        pos = [nltk.pos_tag(sent) for sent in sentences]\n",
    "        return pos\n",
    "    \n",
    "splitter = Splitter()\n",
    "postagger = POSTagger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c615c7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_data = train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c853594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...at your age, the heyday in the blood is tame...' @TheArtofCharm #shakespeareaninsults #hamlet #elizabethan #williamshakespeare valence\n",
      "\n",
      "\n",
      "('...', ':')\n",
      "('at', 'IN')\n",
      "('your', 'PRP$')\n",
      "('age', 'NN')\n",
      "(',', ',')\n",
      "('the', 'DT')\n",
      "('heyday', 'NN')\n",
      "('in', 'IN')\n",
      "('the', 'DT')\n",
      "('blood', 'NN')\n",
      "('is', 'VBZ')\n",
      "('tame', 'JJ')\n",
      "('...', ':')\n",
      "(\"'\", 'POS')\n",
      "('@', 'JJ')\n",
      "('TheArtofCharm', 'NNP')\n",
      "('#', '#')\n",
      "('shakespeareaninsults', 'NNS')\n",
      "('#', '#')\n",
      "('hamlet', 'NN')\n",
      "('#', '#')\n",
      "('elizabethan', 'JJ')\n",
      "('#', '#')\n",
      "('williamshakespeare', 'NN')\n",
      "('valence', 'NN')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(train_pos_data.Tweet.tolist()[3])\n",
    "print(\"\\n\")\n",
    "\n",
    "tweet = train_pos_data.Tweet.tolist()[3]\n",
    "splitted_sentences = splitter.split(tweet)\n",
    "pos_tagged_sentences = postagger.pos_tag(splitted_sentences)\n",
    "for sentence in pos_tagged_sentences:\n",
    "    for words in sentence:\n",
    "        print(words)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b988b2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just because I'm hurting \\nDoesn't mean I'm hurt \\nDoesn't mean I didn't get \\nWhat I deserved \\nNo better and no worse #lost  @coldplay valence\n",
      "\n",
      "\n",
      "('Just', 'RB')\n",
      "('because', 'IN')\n",
      "('I', 'PRP')\n",
      "(\"'m\", 'VBP')\n",
      "('hurting', 'VBG')\n",
      "('\\\\nDoes', 'VBP')\n",
      "(\"n't\", 'RB')\n",
      "('mean', 'VB')\n",
      "('I', 'PRP')\n",
      "(\"'m\", 'VBP')\n",
      "('hurt', 'JJ')\n",
      "('\\\\nDoes', 'VBP')\n",
      "(\"n't\", 'RB')\n",
      "('mean', 'VB')\n",
      "('I', 'PRP')\n",
      "('did', 'VBD')\n",
      "(\"n't\", 'RB')\n",
      "('get', 'VB')\n",
      "('\\\\nWhat', 'RB')\n",
      "('I', 'PRP')\n",
      "('deserved', 'VBD')\n",
      "('\\\\nNo', 'NNP')\n",
      "('better', 'RBR')\n",
      "('and', 'CC')\n",
      "('no', 'DT')\n",
      "('worse', 'JJR')\n",
      "('#', '#')\n",
      "('lost', 'VBN')\n",
      "('@', 'JJ')\n",
      "('coldplay', 'NN')\n",
      "('valence', 'NN')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(train_pos_data.Tweet.tolist()[9])\n",
    "print(\"\\n\")\n",
    "\n",
    "tweet = train_pos_data.Tweet.tolist()[9]\n",
    "splitted_sentences = splitter.split(tweet)\n",
    "pos_tagged_sentences = postagger.pos_tag(splitted_sentences)\n",
    "for sentence in pos_tagged_sentences:\n",
    "    for words in sentence:\n",
    "        print(words)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7046316a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have been a better second half team this season. So there's that.  valence\n",
      "\n",
      "\n",
      "('We', 'PRP')\n",
      "('have', 'VBP')\n",
      "('been', 'VBN')\n",
      "('a', 'DT')\n",
      "('better', 'JJR')\n",
      "('second', 'JJ')\n",
      "('half', 'NN')\n",
      "('team', 'NN')\n",
      "('this', 'DT')\n",
      "('season', 'NN')\n",
      "('.', '.')\n",
      "\n",
      "\n",
      "('So', 'IN')\n",
      "('there', 'EX')\n",
      "(\"'s\", 'VBZ')\n",
      "('that', 'DT')\n",
      "('.', '.')\n",
      "\n",
      "\n",
      "('valence', 'NN')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(train_pos_data.Tweet.tolist()[12])\n",
    "print(\"\\n\")\n",
    "\n",
    "tweet = train_pos_data.Tweet.tolist()[12]\n",
    "splitted_sentences = splitter.split(tweet)\n",
    "pos_tagged_sentences = postagger.pos_tag(splitted_sentences)\n",
    "for sentence in pos_tagged_sentences:\n",
    "    for words in sentence:\n",
    "        print(words)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be46bd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features in training set: 5039\n",
      "Number of features in test set: 5039\n"
     ]
    }
   ],
   "source": [
    "### TASK 3: Extract Unigram Features ###\n",
    "\n",
    "X_train, y_train = train_data[\"Tweet\"], train_data[\"Sentiment\"]\n",
    "X_test, y_test = test_data[\"Tweet\"], test_data[\"Sentiment\"]\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1))  # Unigrams\n",
    "X_train_features = vectorizer.fit_transform(X_train)\n",
    "X_test_features = vectorizer.transform(X_test)\n",
    "\n",
    "\n",
    "print(f\"Number of features in training set: {X_train_features.shape[1]}\")\n",
    "print(f\"Number of features in test set: {X_test_features.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c9897b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.3127\n",
      "Classification Report:\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "      Very Negative (-3)     0.5000    0.0645    0.1143        93\n",
      "Moderately Negative (-2)     0.3179    0.2874    0.3019       167\n",
      "  Slightly Negative (-1)     0.0000    0.0000    0.0000        80\n",
      "             Neutral (0)     0.2986    0.8206    0.4379       262\n",
      "   Slightly Positive (1)     0.1304    0.0280    0.0462       107\n",
      " Moderately Positive (2)     0.0000    0.0000    0.0000        91\n",
      "       Very Positive (3)     0.6774    0.1533    0.2500       137\n",
      "\n",
      "                accuracy                         0.3127       937\n",
      "               macro avg     0.2749    0.1934    0.1643       937\n",
      "            weighted avg     0.3037    0.3127    0.2294       937\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### TASK 4: Train and Evaluate Na√Øve Bayes Classifier ###\n",
    "\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train_features, y_train)\n",
    "\n",
    "\n",
    "y_pred = nb_classifier.predict(X_test_features)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "class_report = classification_report(y_test, y_pred, digits=4, zero_division=0, target_names=[\n",
    "    \"Very Negative (-3)\", \"Moderately Negative (-2)\", \"Slightly Negative (-1)\",\n",
    "    \"Neutral (0)\", \"Slightly Positive (1)\", \"Moderately Positive (2)\", \"Very Positive (3)\"\n",
    "])\n",
    "\n",
    "print(\"Classification Report:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6abbf687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features in training set (Unigram + Bigram): 19390\n",
      "Number of features in test set (Unigram + Bigram): 19390\n",
      "Model Accuracy (Unigram + Bigram): 0.3020\n",
      "Classification Report (Unigram + Bigram):\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "      Very Negative (-3)     0.5000    0.0645    0.1143        93\n",
      "Moderately Negative (-2)     0.2734    0.2275    0.2484       167\n",
      "  Slightly Negative (-1)     0.0000    0.0000    0.0000        80\n",
      "             Neutral (0)     0.2915    0.8244    0.4307       262\n",
      "   Slightly Positive (1)     0.0000    0.0000    0.0000       107\n",
      " Moderately Positive (2)     0.0000    0.0000    0.0000        91\n",
      "       Very Positive (3)     0.7419    0.1679    0.2738       137\n",
      "\n",
      "                accuracy                         0.3020       937\n",
      "               macro avg     0.2581    0.1835    0.1525       937\n",
      "            weighted avg     0.2883    0.3020    0.2161       937\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### TASK 5: Unigram + Bigram Features ###\n",
    "vectorizer_bigram = CountVectorizer(ngram_range=(1, 2))  # Unigram + Bigram\n",
    "X_train_bigram = vectorizer_bigram.fit_transform(X_train)\n",
    "X_test_bigram = vectorizer_bigram.transform(X_test)\n",
    "\n",
    "\n",
    "print(f\"Number of features in training set (Unigram + Bigram): {X_train_bigram.shape[1]}\")\n",
    "print(f\"Number of features in test set (Unigram + Bigram): {X_test_bigram.shape[1]}\")\n",
    "\n",
    "\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train_bigram, y_train)\n",
    "\n",
    "\n",
    "y_pred_bigram = nb_classifier.predict(X_test_bigram)\n",
    "\n",
    "\n",
    "accuracy_bigram = accuracy_score(y_test, y_pred_bigram)\n",
    "print(f\"Model Accuracy (Unigram + Bigram): {accuracy_bigram:.4f}\")\n",
    "\n",
    "\n",
    "class_report_bigram = classification_report(y_test, y_pred_bigram, digits=4, zero_division=0, target_names=[\n",
    "    \"Very Negative (-3)\", \"Moderately Negative (-2)\", \"Slightly Negative (-1)\",\n",
    "    \"Neutral (0)\", \"Slightly Positive (1)\", \"Moderately Positive (2)\", \"Very Positive (3)\"\n",
    "])\n",
    "print(\"Classification Report (Unigram + Bigram):\\n\", class_report_bigram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f20db738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features in training set (Unigram + Bigram + Trigram): 35185\n",
      "Number of features in test set (Unigram + Bigram + Trigram): 35185\n",
      "Model Accuracy (Unigram + Bigram + Trigram): 0.2999\n",
      "Classification Report (Unigram + Bigram + Trigram):\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "      Very Negative (-3)     0.6667    0.0645    0.1176        93\n",
      "Moderately Negative (-2)     0.2698    0.2036    0.2321       167\n",
      "  Slightly Negative (-1)     0.0000    0.0000    0.0000        80\n",
      "             Neutral (0)     0.2855    0.8282    0.4247       262\n",
      "   Slightly Positive (1)     0.0000    0.0000    0.0000       107\n",
      " Moderately Positive (2)     1.0000    0.0110    0.0217        91\n",
      "       Very Positive (3)     0.7667    0.1679    0.2754       137\n",
      "\n",
      "                accuracy                         0.2999       937\n",
      "               macro avg     0.4270    0.1822    0.1531       937\n",
      "            weighted avg     0.4033    0.2999    0.2142       937\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### TASK 6: Unigram + Bigram + Trigram Features ###\n",
    "vectorizer_trigram = CountVectorizer(ngram_range=(1, 3))  # Unigram + Bigram + Trigram\n",
    "X_train_trigram = vectorizer_trigram.fit_transform(X_train)\n",
    "X_test_trigram = vectorizer_trigram.transform(X_test)\n",
    "\n",
    "\n",
    "print(f\"Number of features in training set (Unigram + Bigram + Trigram): {X_train_trigram.shape[1]}\")\n",
    "print(f\"Number of features in test set (Unigram + Bigram + Trigram): {X_test_trigram.shape[1]}\")\n",
    "\n",
    "\n",
    "nb_classifier.fit(X_train_trigram, y_train)\n",
    "\n",
    "\n",
    "y_pred_trigram = nb_classifier.predict(X_test_trigram)\n",
    "\n",
    "\n",
    "accuracy_trigram = accuracy_score(y_test, y_pred_trigram)\n",
    "print(f\"Model Accuracy (Unigram + Bigram + Trigram): {accuracy_trigram:.4f}\")\n",
    "\n",
    "\n",
    "class_report_trigram = classification_report(y_test, y_pred_trigram, digits=4, zero_division=0, target_names=[\n",
    "    \"Very Negative (-3)\", \"Moderately Negative (-2)\", \"Slightly Negative (-1)\",\n",
    "    \"Neutral (0)\", \"Slightly Positive (1)\", \"Moderately Positive (2)\", \"Very Positive (3)\"\n",
    "])\n",
    "print(\"Classification Report (Unigram + Bigram + Trigram):\\n\", class_report_trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "92df3e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy (TF-IDF): 0.2828\n",
      "Classification Report (TF-IDF):\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "      Very Negative (-3)     0.0000    0.0000    0.0000        93\n",
      "Moderately Negative (-2)     0.2647    0.0539    0.0896       167\n",
      "  Slightly Negative (-1)     0.0000    0.0000    0.0000        80\n",
      "             Neutral (0)     0.2838    0.9771    0.4399       262\n",
      "   Slightly Positive (1)     0.0000    0.0000    0.0000       107\n",
      " Moderately Positive (2)     0.0000    0.0000    0.0000        91\n",
      "       Very Positive (3)     0.0000    0.0000    0.0000       137\n",
      "\n",
      "                accuracy                         0.2828       937\n",
      "               macro avg     0.0784    0.1473    0.0756       937\n",
      "            weighted avg     0.1265    0.2828    0.1390       937\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### TASK 7: TF-IDF Feature Extraction for Best Model ###\n",
    "vectorizer_tfidf = TfidfVectorizer(ngram_range=(1, 1))  # TF-IDF for Unigram\n",
    "X_train_tfidf = vectorizer_tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer_tfidf.transform(X_test)\n",
    "\n",
    "\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "\n",
    "y_pred_tfidf = nb_classifier.predict(X_test_tfidf)\n",
    "\n",
    "\n",
    "accuracy_tfidf = accuracy_score(y_test, y_pred_tfidf)\n",
    "print(f\"Model Accuracy (TF-IDF): {accuracy_tfidf:.4f}\")\n",
    "\n",
    "\n",
    "class_report_tfidf = classification_report(y_test, y_pred_tfidf, digits=4, zero_division=0, target_names=[\n",
    "    \"Very Negative (-3)\", \"Moderately Negative (-2)\", \"Slightly Negative (-1)\",\n",
    "    \"Neutral (0)\", \"Slightly Positive (1)\", \"Moderately Positive (2)\", \"Very Positive (3)\"\n",
    "])\n",
    "print(\"Classification Report (TF-IDF):\\n\", class_report_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "05c137ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy (Unigram with Preprocessing): 0.3298\n",
      "Classification Report (Unigram with Preprocessing):\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "      Very Negative (-3)     0.3939    0.1398    0.2063        93\n",
      "Moderately Negative (-2)     0.3096    0.3653    0.3352       167\n",
      "  Slightly Negative (-1)     0.0000    0.0000    0.0000        80\n",
      "             Neutral (0)     0.3129    0.7023    0.4329       262\n",
      "   Slightly Positive (1)     0.1463    0.0561    0.0811       107\n",
      " Moderately Positive (2)     0.3333    0.0110    0.0213        91\n",
      "       Very Positive (3)     0.5867    0.3212    0.4151       137\n",
      "\n",
      "                accuracy                         0.3298       937\n",
      "               macro avg     0.2976    0.2279    0.2131       937\n",
      "            weighted avg     0.3166    0.3298    0.2733       937\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### TASK 8: Preprocessing + Apply Best Model ###\n",
    "from nltk.stem import PorterStemmer \n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    text = text.lower() \n",
    "    text = re.sub(r'\\W', ' ', text)  \n",
    "    text = re.sub(r'\\s+', ' ', text)  \n",
    "    tokens = word_tokenize(text) \n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]  \n",
    "    stemmer = PorterStemmer()  # Initialize stemmer\n",
    "    tokens = [stemmer.stem(word) for word in tokens]  # Apply stemming\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "\n",
    "\n",
    "X_train_preprocessed = X_train.apply(preprocess_text)\n",
    "X_test_preprocessed = X_test.apply(preprocess_text)\n",
    "\n",
    "\n",
    "vectorizer_unigram = CountVectorizer(ngram_range=(1, 1))  # Unigrams only\n",
    "X_train_unigram_preprocessed = vectorizer_unigram.fit_transform(X_train_preprocessed)\n",
    "X_test_unigram_preprocessed = vectorizer_unigram.transform(X_test_preprocessed)\n",
    "\n",
    "\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train_unigram_preprocessed, y_train)\n",
    "y_pred_unigram_preprocessed = nb_classifier.predict(X_test_unigram_preprocessed)\n",
    "\n",
    "\n",
    "accuracy_unigram_preprocessed = accuracy_score(y_test, y_pred_unigram_preprocessed)\n",
    "print(f\"Model Accuracy (Unigram with Preprocessing): {accuracy_unigram_preprocessed:.4f}\")\n",
    "\n",
    "\n",
    "class_report_unigram_preprocessed = classification_report(y_test, y_pred_unigram_preprocessed, digits=4, zero_division=0, target_names=[\n",
    "    \"Very Negative (-3)\", \"Moderately Negative (-2)\", \"Slightly Negative (-1)\",\n",
    "    \"Neutral (0)\", \"Slightly Positive (1)\", \"Moderately Positive (2)\", \"Very Positive (3)\"\n",
    "])\n",
    "print(\"Classification Report (Unigram with Preprocessing):\\n\", class_report_unigram_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1d3db389",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error Analysis (Misclassified Examples):\n",
      "\n",
      "\n",
      "Misclassified examples for sentiment label -3:\n",
      "\n",
      "Tweet: @DPD_UK apparently u left a calling card... @ which address cos it certainly wasn't the address u were supposed to be delivering 2!!! #awful valence\n",
      "Original Sentiment: -3, Predicted Sentiment: 0\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet: @DPD_UK apparently u left a calling card... @ which address cos it certainly wasn't the address u were supposed to be delivering 2!!! #awful valence\n",
      "Original Sentiment: -3, Predicted Sentiment: 0\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet: discouraged valence\n",
      "Original Sentiment: -3, Predicted Sentiment: 0\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Misclassified examples for sentiment label -2:\n",
      "\n",
      "Tweet: I'm still feeling some type of way about Viserion. #GameOfThrones #crying #stresseating valence\n",
      "Original Sentiment: -2, Predicted Sentiment: 0\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet: @COFFEECOWal Really Sad News, it's been a pleasure over the years, all the best for the future. valence\n",
      "Original Sentiment: -2, Predicted Sentiment: 0\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet: ‚ÄúTell me, Doctor, are you afraid of #death?'\\n'I guess it depends on how you #die.‚Äù valence\n",
      "Original Sentiment: -2, Predicted Sentiment: -3\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Misclassified examples for sentiment label -1:\n",
      "\n",
      "Tweet: But also tomorrow's goal is to clean my room so like greatttt #sarcasm valence\n",
      "Original Sentiment: -1, Predicted Sentiment: 0\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet: @LondonEconomic Sometimes our judiciary just leaves you breathless and speechless. valence\n",
      "Original Sentiment: -1, Predicted Sentiment: 0\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet: @Chris_Meloni Also? #irony valence\n",
      "Original Sentiment: -1, Predicted Sentiment: 0\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Misclassified examples for sentiment label 0:\n",
      "\n",
      "Tweet: All the proud parents on fb about their kids school report and am shitting myself for Graces arriving üòÇüòÇüòÇ  #troublemaker valence\n",
      "Original Sentiment: 0, Predicted Sentiment: -3\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet: 'A #pessimist sees the difficulty in every #opportunity; an #optimist sees the opportunity in every difficulty.' ‚ÄîWinston Churchill #quote valence\n",
      "Original Sentiment: 0, Predicted Sentiment: 1\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet: Up early. Kicking ass and taking names. #offense. valence\n",
      "Original Sentiment: 0, Predicted Sentiment: -2\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Misclassified examples for sentiment label 1:\n",
      "\n",
      "Tweet: Great start. Exciting new innovation = new challenges. @VisaSecurity #VSS2017 #brilliance valence\n",
      "Original Sentiment: 1, Predicted Sentiment: 0\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet: @ufc wow, Snoop is smoking up good and it appears Faber has a contact high. Thanks for this amazing commentary. #ContenderSeries #sarcasm valence\n",
      "Original Sentiment: 1, Predicted Sentiment: 0\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet: @jessmacf_ But his mannerisms are hilarious !! valence\n",
      "Original Sentiment: 1, Predicted Sentiment: 0\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Misclassified examples for sentiment label 2:\n",
      "\n",
      "Tweet: @WorldFringeDay Heehee. I did chuckle to myself when i saw what it actually was, so you did get a laugh out if me. \\nüòÄ valence\n",
      "Original Sentiment: 2, Predicted Sentiment: 0\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet: @WalmartToday your hitting it spot on with your commercials. Love the one with the town coming to eat and bringing chairs. #brilliant valence\n",
      "Original Sentiment: 2, Predicted Sentiment: 0\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet: She'll leave you with a smile valence\n",
      "Original Sentiment: 2, Predicted Sentiment: 0\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Misclassified examples for sentiment label 3:\n",
      "\n",
      "Tweet: Today is already off to a great start..... üôÑ  valence\n",
      "Original Sentiment: 3, Predicted Sentiment: 0\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet: You turned my world with a smile, and you take my heart with a kiss valence\n",
      "Original Sentiment: 3, Predicted Sentiment: 0\n",
      "--------------------------------------------------------------------------------\n",
      "Tweet: Just tried @GoodmanBakery for the 1st time... GF for 13 yrs &amp; these are some of the best baked goods I've ever had! DF is a bonus! #yummy valence\n",
      "Original Sentiment: 3, Predicted Sentiment: 0\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "### TASK 10: Error Analysis  ###\n",
    "\n",
    "print(\"\\nError Analysis (Misclassified Examples):\\n\")\n",
    "\n",
    "\n",
    "misclassified = test_data[y_test != y_pred_unigram_preprocessed].copy()\n",
    "misclassified[\"Original Sentiment\"] = y_test[y_test != y_pred_unigram_preprocessed]\n",
    "misclassified[\"Predicted Sentiment\"] = y_pred_unigram_preprocessed[y_test != y_pred_unigram_preprocessed]\n",
    "\n",
    "\n",
    "for label in sorted(y_test.unique()):  \n",
    "    print(f\"\\nMisclassified examples for sentiment label {label}:\\n\")\n",
    "    \n",
    "    \n",
    "    samples = misclassified[misclassified[\"Original Sentiment\"] == label].sample(3, replace=True)\n",
    "    \n",
    "    \n",
    "    for index, row in samples.iterrows():\n",
    "        print(f\"Tweet: {row['Tweet']}\")\n",
    "        print(f\"Original Sentiment: {row['Original Sentiment']}, Predicted Sentiment: {row['Predicted Sentiment']}\")\n",
    "        print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3630b195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Accuracy (Three-way classification): 0.5816\n",
      "Classification Report (Three-way Classification):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative     0.6087    0.4846    0.5396       260\n",
      "     Neutral     0.5545    0.8040    0.6564       449\n",
      "    Positive     0.7342    0.2544    0.3779       228\n",
      "\n",
      "    accuracy                         0.5816       937\n",
      "   macro avg     0.6325    0.5143    0.5246       937\n",
      "weighted avg     0.6133    0.5816    0.5562       937\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### TASK 11: Three-Way vs. Seven-Way Classification ###\n",
    "\n",
    "sentiment_mapping = {\n",
    "    -3: \"negative\", -2: \"negative\",\n",
    "    -1: \"neutral\", 0: \"neutral\", 1: \"neutral\",\n",
    "    2: \"positive\", 3: \"positive\"\n",
    "}\n",
    "\n",
    "\n",
    "y_train_3way = y_train.map(sentiment_mapping)\n",
    "y_test_3way = y_test.map(sentiment_mapping)\n",
    "\n",
    "nb_classifier.fit(X_train_unigram_preprocessed, y_train_3way)\n",
    "\n",
    "y_pred_3way = nb_classifier.predict(X_test_unigram_preprocessed)\n",
    "\n",
    "\n",
    "accuracy_3way = accuracy_score(y_test_3way, y_pred_3way)\n",
    "print(f\"\\nModel Accuracy (Three-way classification): {accuracy_3way:.4f}\")\n",
    "\n",
    "\n",
    "class_report_3way = classification_report(y_test_3way, y_pred_3way, digits=4, zero_division=0, target_names=[\"Negative\", \"Neutral\", \"Positive\"])\n",
    "print(\"Classification Report (Three-way Classification):\\n\", class_report_3way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d38a32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textmining",
   "language": "python",
   "name": "textmining"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
